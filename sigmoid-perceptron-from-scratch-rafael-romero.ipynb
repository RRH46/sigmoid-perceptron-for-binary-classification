{"cells":[{"cell_type":"markdown","metadata":{},"source":["Este bloque de código prepara el entorno de trabajo para el análisis de datos y el modelado de machine learning. Instala una librería que facilita el acceso a conjuntos de datos, y luego importa diversas bibliotecas necesarias para la manipulación de datos, visualización y creación de modelos de machine learning."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37019,"status":"ok","timestamp":1726229336734,"user":{"displayName":"Andrés Hernández Gutiérrez","userId":"09168378548171975941"},"user_tz":-600},"id":"REyK8cG6Qisu","outputId":"f2c6ce0d-0539-4e44-ca3d-274be2288b27"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting ucimlrepo\n","  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n","Requirement already satisfied: pandas>=1.0.0 in c:\\users\\romer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ucimlrepo) (2.2.2)\n","Requirement already satisfied: certifi>=2020.12.5 in c:\\users\\romer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ucimlrepo) (2024.7.4)\n","Requirement already satisfied: numpy>=1.23.2 in c:\\users\\romer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\romer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in c:\\users\\romer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in c:\\users\\romer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n","Requirement already satisfied: six>=1.5 in c:\\users\\romer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n","Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n","Installing collected packages: ucimlrepo\n","Successfully installed ucimlrepo-0.0.7\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip is available: 24.0 -> 24.2\n","[notice] To update, run: C:\\Users\\romer\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"]}],"source":["# Instala el paquete ucimlrepo, que proporciona acceso a conjuntos de datos del Repositorio de Aprendizaje Automático de UCI\n","!pip install ucimlrepo\n","\n","# Importa la función fetch_ucirepo del paquete ucimlrepo para descargar conjuntos de datos\n","from ucimlrepo import fetch_ucirepo\n","\n","# Importa pandas para la manipulación y análisis de datos\n","import pandas as pd\n","\n","# Importa matplotlib para crear visualizaciones\n","import matplotlib.pyplot as plt\n","\n","# Importa numpy para operaciones numéricas\n","import numpy as np\n","\n","# Importa TensorFlow para construir y entrenar modelos de machine learning\n","import tensorflow as tf\n","\n","# Importa train_test_split para dividir el conjunto de datos en conjuntos de entrenamiento y prueba\n","from sklearn.model_selection import train_test_split\n","\n","# Importa StandardScaler para la normalización de características\n","from sklearn.preprocessing import StandardScaler\n"]},{"cell_type":"markdown","metadata":{},"source":["Este código descarga el conjunto de datos de detección de ocupación desde el Repositorio de Aprendizaje Automático de UCI. Luego, extrae los datos originales en un DataFrame que será utilizado para análisis y modelado. El output es el conjunto de datos 'occupancy-detection', almacenado en la variable data. "]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":2040,"status":"ok","timestamp":1726229340831,"user":{"displayName":"Andrés Hernández Gutiérrez","userId":"09168378548171975941"},"user_tz":-600},"id":"VR0P_ZhYQisw"},"outputs":[],"source":["# Descarga el conjunto de datos 'occupancy-detection'\n","# utilizando el id=357\n","occupancy_detection = fetch_ucirepo(id=357)\n","\n","# Construye los conjuntos de datos de características y de objetivo\n","data = occupancy_detection.data.original\n"]},{"cell_type":"markdown","metadata":{},"source":["Este bloque de código prepara el DataFrame df eliminando columnas innecesarias y asegurándose de que todos los datos sean numéricos. Las filas que contengan valores faltantes son eliminadas para garantizar la calidad del conjunto de datos antes de realizar el entrenamiento. El output de este bloque es un DataFrame llamado df que contiene solo las columnas numéricas del conjunto de datos original, excluyendo 'date' e 'id'."]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":666,"status":"ok","timestamp":1726229343639,"user":{"displayName":"Andrés Hernández Gutiérrez","userId":"09168378548171975941"},"user_tz":-600},"id":"rew6AD7bQisw"},"outputs":[],"source":["# Elimina las columnas 'date' e 'id' del DataFrame original\n","df = data.drop(['date', 'id'], axis=1)\n","\n","# Convierte todas las columnas del DataFrame a tipo numérico,\n","# reemplazando los errores por NaN\n","df[df.columns] = df[df.columns].apply(pd.to_numeric, errors='coerce')\n","\n","# Elimina las filas que contienen valores NaN\n","df = df.dropna()\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"gfl5mAE1Qisw","outputId":"884f7299-2296-4c7a-ed22-05f11cff96f1"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Temperature</th>\n","      <th>Humidity</th>\n","      <th>Light</th>\n","      <th>CO2</th>\n","      <th>HumidityRatio</th>\n","      <th>Occupancy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>23.180</td>\n","      <td>27.2720</td>\n","      <td>426.00</td>\n","      <td>721.25</td>\n","      <td>0.004793</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>23.150</td>\n","      <td>27.2675</td>\n","      <td>429.50</td>\n","      <td>714.00</td>\n","      <td>0.004783</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>23.150</td>\n","      <td>27.2450</td>\n","      <td>426.00</td>\n","      <td>713.50</td>\n","      <td>0.004779</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>23.150</td>\n","      <td>27.2000</td>\n","      <td>426.00</td>\n","      <td>708.25</td>\n","      <td>0.004772</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>23.100</td>\n","      <td>27.2000</td>\n","      <td>426.00</td>\n","      <td>704.50</td>\n","      <td>0.004757</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>20557</th>\n","      <td>20.815</td>\n","      <td>27.7175</td>\n","      <td>429.75</td>\n","      <td>1505.25</td>\n","      <td>0.004213</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>20558</th>\n","      <td>20.865</td>\n","      <td>27.7450</td>\n","      <td>423.50</td>\n","      <td>1514.50</td>\n","      <td>0.004230</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>20559</th>\n","      <td>20.890</td>\n","      <td>27.7450</td>\n","      <td>423.50</td>\n","      <td>1521.50</td>\n","      <td>0.004237</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>20560</th>\n","      <td>20.890</td>\n","      <td>28.0225</td>\n","      <td>418.75</td>\n","      <td>1632.00</td>\n","      <td>0.004279</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>20561</th>\n","      <td>21.000</td>\n","      <td>28.1000</td>\n","      <td>409.00</td>\n","      <td>1864.00</td>\n","      <td>0.004321</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>20560 rows × 6 columns</p>\n","</div>"],"text/plain":["       Temperature  Humidity   Light      CO2  HumidityRatio  Occupancy\n","0           23.180   27.2720  426.00   721.25       0.004793        1.0\n","1           23.150   27.2675  429.50   714.00       0.004783        1.0\n","2           23.150   27.2450  426.00   713.50       0.004779        1.0\n","3           23.150   27.2000  426.00   708.25       0.004772        1.0\n","4           23.100   27.2000  426.00   704.50       0.004757        1.0\n","...            ...       ...     ...      ...            ...        ...\n","20557       20.815   27.7175  429.75  1505.25       0.004213        1.0\n","20558       20.865   27.7450  423.50  1514.50       0.004230        1.0\n","20559       20.890   27.7450  423.50  1521.50       0.004237        1.0\n","20560       20.890   28.0225  418.75  1632.00       0.004279        1.0\n","20561       21.000   28.1000  409.00  1864.00       0.004321        1.0\n","\n","[20560 rows x 6 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"markdown","metadata":{},"source":["Este bloque de código utiliza el método describe() de pandas para obtener estadísticas descriptivas del DataFrame df. Esto incluye medidas como la media, la desviación estándar, los valores mínimo y máximo, y los cuartiles para cada una de las columnas numéricas. La tabla que muestra las estadísticas descriptivas del DataFrame df. Esta tabla proporciona información útil sobre la distribución y las características de los datos, algunas cosas que podemos observar son: \n","\n","Los datos reflejan un entorno controlado donde las temperaturas y humedades están dentro de límites razonables para espacios interiores.\n","La presencia de valores de luz que van desde 0 hasta casi 1700 lux indica variaciones significativas en la iluminación del espacio.\n","Un 23.1% de ocupación indica que, en promedio, más del 75% de las observaciones son de espacios desocupados."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"executionInfo":{"elapsed":562,"status":"ok","timestamp":1726229347094,"user":{"displayName":"Andrés Hernández Gutiérrez","userId":"09168378548171975941"},"user_tz":-600},"id":"ELCVREAKQisw","outputId":"cce4a981-4706-406f-f635-fdfd47f54eeb"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Temperature</th>\n","      <th>Humidity</th>\n","      <th>Light</th>\n","      <th>CO2</th>\n","      <th>HumidityRatio</th>\n","      <th>Occupancy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>20560.000000</td>\n","      <td>20560.000000</td>\n","      <td>20560.000000</td>\n","      <td>20560.000000</td>\n","      <td>20560.000000</td>\n","      <td>20560.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>20.906212</td>\n","      <td>27.655925</td>\n","      <td>130.756622</td>\n","      <td>690.553276</td>\n","      <td>0.004228</td>\n","      <td>0.231031</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>1.055315</td>\n","      <td>4.982154</td>\n","      <td>210.430875</td>\n","      <td>311.201281</td>\n","      <td>0.000768</td>\n","      <td>0.421503</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>19.000000</td>\n","      <td>16.745000</td>\n","      <td>0.000000</td>\n","      <td>412.750000</td>\n","      <td>0.002674</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>20.200000</td>\n","      <td>24.500000</td>\n","      <td>0.000000</td>\n","      <td>460.000000</td>\n","      <td>0.003719</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>20.700000</td>\n","      <td>27.290000</td>\n","      <td>0.000000</td>\n","      <td>565.416667</td>\n","      <td>0.004292</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>21.525000</td>\n","      <td>31.290000</td>\n","      <td>301.000000</td>\n","      <td>804.666667</td>\n","      <td>0.004832</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>24.408333</td>\n","      <td>39.500000</td>\n","      <td>1697.250000</td>\n","      <td>2076.500000</td>\n","      <td>0.006476</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        Temperature      Humidity         Light           CO2  HumidityRatio  \\\n","count  20560.000000  20560.000000  20560.000000  20560.000000   20560.000000   \n","mean      20.906212     27.655925    130.756622    690.553276       0.004228   \n","std        1.055315      4.982154    210.430875    311.201281       0.000768   \n","min       19.000000     16.745000      0.000000    412.750000       0.002674   \n","25%       20.200000     24.500000      0.000000    460.000000       0.003719   \n","50%       20.700000     27.290000      0.000000    565.416667       0.004292   \n","75%       21.525000     31.290000    301.000000    804.666667       0.004832   \n","max       24.408333     39.500000   1697.250000   2076.500000       0.006476   \n","\n","          Occupancy  \n","count  20560.000000  \n","mean       0.231031  \n","std        0.421503  \n","min        0.000000  \n","25%        0.000000  \n","50%        0.000000  \n","75%        0.000000  \n","max        1.000000  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Genera estadísticas descriptivas del DataFrame df\n","df.describe()\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":381,"status":"ok","timestamp":1726229349123,"user":{"displayName":"Andrés Hernández Gutiérrez","userId":"09168378548171975941"},"user_tz":-600},"id":"_qmL27_KQisw"},"outputs":[],"source":["# Establece una semilla aleatoria para TensorFlow para garantizar la reproducibilidad\n","tf.random.set_seed(4500)\n"]},{"cell_type":"markdown","metadata":{},"source":["Aqui se separa el conjunto de datos en dos partes: X, que contiene las características, todas las columnas excepto 'Occupancy', y y, que contiene la etiqueta o variable objetivo ('Occupancy')."]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":417,"status":"ok","timestamp":1726229350763,"user":{"displayName":"Andrés Hernández Gutiérrez","userId":"09168378548171975941"},"user_tz":-600},"id":"4sIFY_kAQisw"},"outputs":[],"source":["# Crea el conjunto de características X eliminando la columna 'Occupancy' del DataFrame df\n","X = df.drop([\"Occupancy\"], axis=1)\n","\n","# Crea el conjunto de etiquetas y a partir de la columna 'Occupancy' del DataFrame df\n","y = df['Occupancy']\n"]},{"cell_type":"markdown","metadata":{},"source":["Se utiliza la función train_test_split de scikit-learn para dividir los conjuntos de características (X) y etiquetas (y) en conjuntos de entrenamiento y prueba."]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":305,"status":"ok","timestamp":1726229352060,"user":{"displayName":"Andrés Hernández Gutiérrez","userId":"09168378548171975941"},"user_tz":-600},"id":"6yPyLEblQisw"},"outputs":[],"source":["# Divide el conjunto de datos en conjuntos de entrenamiento y prueba\n","# test_size=0.2 indica que el 20% de los datos se utilizará para pruebas\n","# random_state=42 asegura que la división sea reproducible\n","# shuffle=True mezcla los datos antes de la división\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n"]},{"cell_type":"markdown","metadata":{},"source":["Este bloque de código normaliza los conjuntos de datos de características (X_train y X_test) utilizando el StandardScaler."]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1726229353635,"user":{"displayName":"Andrés Hernández Gutiérrez","userId":"09168378548171975941"},"user_tz":-600},"id":"O7J3VULnQisx"},"outputs":[],"source":["# Crea una instancia del objeto StandardScaler para normalizar los datos\n","scaler = StandardScaler()\n","\n","# Ajusta el scaler a los datos de entrenamiento y transforma X_train\n","X_train = scaler.fit_transform(X_train)\n","\n","# Transforma X_test utilizando los parámetros ajustados en X_train\n","X_test = scaler.transform(X_test)\n"]},{"cell_type":"markdown","metadata":{},"source":["Este bloque define una clase NeuronModel, que implementa un modelo de neurona simple utilizando un enfoque de retropropagación para entrenar. Incluye métodos para la propagación hacia adelante, el cálculo de costos, la actualización de parámetros, y la predicción, así como la visualización del costo a lo largo de las iteraciones."]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":332,"status":"ok","timestamp":1726229356530,"user":{"displayName":"Andrés Hernández Gutiérrez","userId":"09168378548171975941"},"user_tz":-600},"id":"sxdZAxWxQisx"},"outputs":[],"source":["# Importa la función sigmoide (expit) de la biblioteca scipy\n","from scipy.special import expit\n","\n","# Define la clase NeuronModel para crear y entrenar un modelo de neurona\n","class NeuronModel():\n","\n","    # Inicializa el modelo con los datos de entrada y parámetros\n","    def __init__(self, X, y, learning_rate=0.01, error_threshold=0.001) -> None:\n","        # Verifica que las matrices de entrada no estén vacías\n","        assert X.size != 0, \"X cannot be empty\"\n","        assert y.size != 0, \"y cannot be empty\"\n","        assert learning_rate > 0, \"learning rate must be positive\"\n","\n","        # Convierte X a un array de numpy si no lo es\n","        if not isinstance(X, np.ndarray):\n","            X = X.to_numpy()\n","\n","        # Convierte y a un array de numpy y lo reestructura\n","        if not isinstance(y, np.ndarray):\n","            y = y.to_numpy().reshape(-1, 1)\n","\n","        # Inicializa las variables del modelo\n","        self.X = X\n","        self.y = y\n","        self.learning_rate = learning_rate\n","        self.w = np.zeros((X.shape[1], 1))  # Inicializa los pesos\n","        self.b = np.zeros((1, 1))  # Inicializa el sesgo\n","        self.N = X.shape[0]  # Número de ejemplos\n","        self.J_iter = list()  # Lista para almacenar el costo por iteración\n","        self.stopping_tolerance = error_threshold  # Umbral de error para detener el entrenamiento\n","\n","    # Calcula la función logística\n","    def compute_logistic(self, w, b, X):\n","        return expit(X @ w + b)\n","\n","    # Calcula el costo utilizando la función de costo logístico\n","    def compute_cost(self, y_hat, y, N):\n","        L = y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat)  # Cálculo del costo logístico\n","        J = -L.sum() / N  # Promedio del costo\n","        return J\n","\n","    # Propagación hacia adelante\n","    def forward_propagation(self, w, b, X):\n","        a = self.compute_logistic(w, b, X)  # Calcula la salida\n","        return a\n","\n","    # Propagación hacia atrás para calcular los gradientes\n","    def backward_propagation(self, y_hat, y, w, X):\n","        N = X.shape[0]  # Número de ejemplos\n","        # Calcula el gradiente para los pesos\n","        gradient_w = np.multiply(y_hat - y, X).sum(axis=0) / N\n","        gradient_w = gradient_w.reshape(w.shape)\n","        # Calcula el gradiente para el sesgo\n","        gradient_b = (y_hat - y).sum() / N\n","        gradient_b = gradient_b.reshape(-1, 1)\n","        return gradient_w, gradient_b\n","\n","    # Actualiza los parámetros utilizando el gradiente\n","    def update_parameters(self, param, gradient):\n","        return np.subtract(param, np.multiply(self.learning_rate, gradient))\n","\n","    # Entrena el modelo\n","    def train(self, verbose=0):\n","        # Propagación hacia adelante inicial\n","        y_hat = self.forward_propagation(self.w, self.b, self.X)\n","        J_prev = self.compute_cost(y_hat, self.y, self.N)  # Costo anterior\n","        J, current_percentage_error = 0, 100  # Inicializa el costo actual y el error\n","        w, b = self.w, self.b\n","\n","        # Bucle de entrenamiento hasta que el error sea menor que el umbral\n","        while current_percentage_error > self.stopping_tolerance:\n","            J_prev = J\n","\n","            y_hat = self.forward_propagation(w, b, self.X)  # Propagación hacia adelante\n","\n","            # Calcula los gradientes\n","            gradient_w, gradient_b = self.backward_propagation(y_hat, self.y, w, self.X)\n","\n","            # Actualiza los parámetros\n","            w = self.update_parameters(w, gradient_w)\n","            b = self.update_parameters(b, gradient_b)\n","\n","            y_hat = self.forward_propagation(w, b, self.X)  # Propagación hacia adelante nuevamente\n","            J = self.compute_cost(y_hat, self.y, self.N)  # Calcula el nuevo costo\n","            self.J_iter.append(J)  # Almacena el costo\n","\n","            # Calcula el error porcentual\n","            current_percentage_error = np.abs((J - J_prev) / J) * 100\n","\n","            # Imprime información si verbose es mayor que 0\n","            if verbose:\n","                print(f\"J_previous: {J_prev:8.6f} \\t\"\n","                      f\"J_current: {J:8.6f} \\t\"\n","                      f\"Error: {current_percentage_error:8.6f}\")\n","\n","        # Almacena los parámetros finales\n","        self.w = w\n","        self.b = b\n","\n","    # Realiza predicciones sobre nuevos datos\n","    def predict(self, X):\n","        a = self.forward_propagation(self.w, self.b, X)  # Propagación hacia adelante\n","        return a\n","\n","    # Grafica la función de costo a lo largo de las iteraciones\n","    def plot_cost_function(self):\n","        plt.plot(self.J_iter)\n","        plt.xlabel('Iteración')\n","        plt.ylabel(r\"$J_{\\mathbf{w}}$\")  # Etiqueta del eje y\n","\n","    # Evalúa el rendimiento del modelo\n","    def evaluate(self, y_hat, y):\n","        # Convierte y a un array de numpy si no lo es\n","        if not isinstance(y, np.ndarray):\n","            y = y.to_numpy().reshape(-1, 1)\n","\n","        # Clasifica las predicciones\n","        y_hat[y_hat >= 0.5] = 1\n","        y_hat[y_hat < 0.5] = 0\n","\n","        # Calcula la tasa de error\n","        err = np.where((np.abs(y - y_hat) > 0) == True)[0]\n","\n","        return 1 - err.shape[0] / y.shape[0]  # Tasa de aciertos\n","\n","    # Obtiene los parámetros del modelo (pesos y sesgo)\n","    def get_parameters(self):\n","        return np.vstack((self.w, self.b))\n"]},{"cell_type":"markdown","metadata":{},"source":["Este bloque de código crea una instancia del modelo de neurona utilizando el conjunto de datos de entrenamiento (X_train y y_train) con un tasa de aprendizaje de 1 y un umbral de error de 0.01. Luego, llama al método train para entrenar el modelo y muestra información sobre el costo.\n","\n","El output muestra la evolución del costo (J) y el error porcentual durante el entrenamiento del modelo\n","Primera iteración: El costo comienza en 0 y luego aumenta a 0.434288, con un error del 100% porque no hay comparación válida inicial.\n","Convergencia: A medida que avanzan las iteraciones, el costo disminuye consistentemente, indicando que el modelo está aprendiendo.\n","Últimas iteraciones: Los valores de J_current se estabilizan en torno a 0.056, y el error baja a menos de 0.01%, sugiriendo que el modelo ha convergido y ajustado bien a los datos.\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11330,"status":"ok","timestamp":1726229552006,"user":{"displayName":"Andrés Hernández Gutiérrez","userId":"09168378548171975941"},"user_tz":-600},"id":"NCoQ267PQisx","outputId":"a0402f07-057c-4857-f4c2-12bb0ffd7cf8"},"outputs":[{"name":"stdout","output_type":"stream","text":["J_previous: 0.000000 \tJ_current: 0.434288 \tError: 100.000000\n","J_previous: 0.434288 \tJ_current: 0.337854 \tError: 28.542931\n","J_previous: 0.337854 \tJ_current: 0.284542 \tError: 18.736343\n","J_previous: 0.284542 \tJ_current: 0.249663 \tError: 13.970439\n","J_previous: 0.249663 \tJ_current: 0.224651 \tError: 11.133710\n","J_previous: 0.224651 \tJ_current: 0.205647 \tError: 9.240989\n","J_previous: 0.205647 \tJ_current: 0.190621 \tError: 7.882361\n","J_previous: 0.190621 \tJ_current: 0.178390 \tError: 6.856745\n","J_previous: 0.178390 \tJ_current: 0.168207 \tError: 6.053642\n","J_previous: 0.168207 \tJ_current: 0.159579 \tError: 5.407044\n","J_previous: 0.159579 \tJ_current: 0.152161 \tError: 4.874943\n","J_previous: 0.152161 \tJ_current: 0.145707 \tError: 4.429250\n","J_previous: 0.145707 \tJ_current: 0.140035 \tError: 4.050434\n","J_previous: 0.140035 \tJ_current: 0.135007 \tError: 3.724473\n","J_previous: 0.135007 \tJ_current: 0.130516 \tError: 3.441032\n","J_previous: 0.130516 \tJ_current: 0.126478 \tError: 3.192321\n","J_previous: 0.126478 \tJ_current: 0.122827 \tError: 2.972356\n","J_previous: 0.122827 \tJ_current: 0.119509 \tError: 2.776462\n","J_previous: 0.119509 \tJ_current: 0.116480 \tError: 2.600933\n","J_previous: 0.116480 \tJ_current: 0.113702 \tError: 2.442794\n","J_previous: 0.113702 \tJ_current: 0.111146 \tError: 2.299625\n","J_previous: 0.111146 \tJ_current: 0.108786 \tError: 2.169442\n","J_previous: 0.108786 \tJ_current: 0.106600 \tError: 2.050597\n","J_previous: 0.106600 \tJ_current: 0.104570 \tError: 1.941713\n","J_previous: 0.104570 \tJ_current: 0.102679 \tError: 1.841629\n","J_previous: 0.102679 \tJ_current: 0.100913 \tError: 1.749358\n","J_previous: 0.100913 \tJ_current: 0.099262 \tError: 1.664058\n","J_previous: 0.099262 \tJ_current: 0.097713 \tError: 1.585002\n","J_previous: 0.097713 \tJ_current: 0.096258 \tError: 1.511562\n","J_previous: 0.096258 \tJ_current: 0.094888 \tError: 1.443192\n","J_previous: 0.094888 \tJ_current: 0.093597 \tError: 1.379412\n","J_previous: 0.093597 \tJ_current: 0.092378 \tError: 1.319805\n","J_previous: 0.092378 \tJ_current: 0.091225 \tError: 1.263998\n","J_previous: 0.091225 \tJ_current: 0.090133 \tError: 1.211663\n","J_previous: 0.090133 \tJ_current: 0.089097 \tError: 1.162509\n","J_previous: 0.089097 \tJ_current: 0.088114 \tError: 1.116276\n","J_previous: 0.088114 \tJ_current: 0.087178 \tError: 1.072729\n","J_previous: 0.087178 \tJ_current: 0.086288 \tError: 1.031659\n","J_previous: 0.086288 \tJ_current: 0.085440 \tError: 0.992878\n","J_previous: 0.085440 \tJ_current: 0.084631 \tError: 0.956215\n","J_previous: 0.084631 \tJ_current: 0.083858 \tError: 0.921517\n","J_previous: 0.083858 \tJ_current: 0.083119 \tError: 0.888642\n","J_previous: 0.083119 \tJ_current: 0.082413 \tError: 0.857463\n","J_previous: 0.082413 \tJ_current: 0.081736 \tError: 0.827866\n","J_previous: 0.081736 \tJ_current: 0.081087 \tError: 0.799742\n","J_previous: 0.081087 \tJ_current: 0.080465 \tError: 0.772995\n","J_previous: 0.080465 \tJ_current: 0.079868 \tError: 0.747536\n","J_previous: 0.079868 \tJ_current: 0.079295 \tError: 0.723284\n","J_previous: 0.079295 \tJ_current: 0.078744 \tError: 0.700162\n","J_previous: 0.078744 \tJ_current: 0.078213 \tError: 0.678101\n","J_previous: 0.078213 \tJ_current: 0.077703 \tError: 0.657038\n","J_previous: 0.077703 \tJ_current: 0.077211 \tError: 0.636913\n","J_previous: 0.077211 \tJ_current: 0.076737 \tError: 0.617670\n","J_previous: 0.076737 \tJ_current: 0.076280 \tError: 0.599260\n","J_previous: 0.076280 \tJ_current: 0.075839 \tError: 0.581635\n","J_previous: 0.075839 \tJ_current: 0.075413 \tError: 0.564751\n","J_previous: 0.075413 \tJ_current: 0.075001 \tError: 0.548568\n","J_previous: 0.075001 \tJ_current: 0.074604 \tError: 0.533046\n","J_previous: 0.074604 \tJ_current: 0.074219 \tError: 0.518152\n","J_previous: 0.074219 \tJ_current: 0.073847 \tError: 0.503851\n","J_previous: 0.073847 \tJ_current: 0.073487 \tError: 0.490113\n","J_previous: 0.073487 \tJ_current: 0.073138 \tError: 0.476909\n","J_previous: 0.073138 \tJ_current: 0.072800 \tError: 0.464211\n","J_previous: 0.072800 \tJ_current: 0.072473 \tError: 0.451995\n","J_previous: 0.072473 \tJ_current: 0.072155 \tError: 0.440237\n","J_previous: 0.072155 \tJ_current: 0.071847 \tError: 0.428913\n","J_previous: 0.071847 \tJ_current: 0.071548 \tError: 0.418004\n","J_previous: 0.071548 \tJ_current: 0.071257 \tError: 0.407489\n","J_previous: 0.071257 \tJ_current: 0.070975 \tError: 0.397350\n","J_previous: 0.070975 \tJ_current: 0.070701 \tError: 0.387569\n","J_previous: 0.070701 \tJ_current: 0.070435 \tError: 0.378130\n","J_previous: 0.070435 \tJ_current: 0.070176 \tError: 0.369017\n","J_previous: 0.070176 \tJ_current: 0.069924 \tError: 0.360216\n","J_previous: 0.069924 \tJ_current: 0.069679 \tError: 0.351712\n","J_previous: 0.069679 \tJ_current: 0.069440 \tError: 0.343493\n","J_previous: 0.069440 \tJ_current: 0.069208 \tError: 0.335546\n","J_previous: 0.069208 \tJ_current: 0.068982 \tError: 0.327860\n","J_previous: 0.068982 \tJ_current: 0.068762 \tError: 0.320423\n","J_previous: 0.068762 \tJ_current: 0.068547 \tError: 0.313224\n","J_previous: 0.068547 \tJ_current: 0.068338 \tError: 0.306255\n","J_previous: 0.068338 \tJ_current: 0.068134 \tError: 0.299505\n","J_previous: 0.068134 \tJ_current: 0.067935 \tError: 0.292965\n","J_previous: 0.067935 \tJ_current: 0.067741 \tError: 0.286627\n","J_previous: 0.067741 \tJ_current: 0.067551 \tError: 0.280482\n","J_previous: 0.067551 \tJ_current: 0.067366 \tError: 0.274524\n","J_previous: 0.067366 \tJ_current: 0.067186 \tError: 0.268744\n","J_previous: 0.067186 \tJ_current: 0.067009 \tError: 0.263137\n","J_previous: 0.067009 \tJ_current: 0.066837 \tError: 0.257694\n","J_previous: 0.066837 \tJ_current: 0.066669 \tError: 0.252410\n","J_previous: 0.066669 \tJ_current: 0.066504 \tError: 0.247278\n","J_previous: 0.066504 \tJ_current: 0.066344 \tError: 0.242294\n","J_previous: 0.066344 \tJ_current: 0.066186 \tError: 0.237451\n","J_previous: 0.066186 \tJ_current: 0.066033 \tError: 0.232745\n","J_previous: 0.066033 \tJ_current: 0.065882 \tError: 0.228170\n","J_previous: 0.065882 \tJ_current: 0.065735 \tError: 0.223721\n","J_previous: 0.065735 \tJ_current: 0.065591 \tError: 0.219395\n","J_previous: 0.065591 \tJ_current: 0.065451 \tError: 0.215186\n","J_previous: 0.065451 \tJ_current: 0.065313 \tError: 0.211090\n","J_previous: 0.065313 \tJ_current: 0.065178 \tError: 0.207105\n","J_previous: 0.065178 \tJ_current: 0.065045 \tError: 0.203224\n","J_previous: 0.065045 \tJ_current: 0.064916 \tError: 0.199446\n","J_previous: 0.064916 \tJ_current: 0.064789 \tError: 0.195767\n","J_previous: 0.064789 \tJ_current: 0.064665 \tError: 0.192182\n","J_previous: 0.064665 \tJ_current: 0.064543 \tError: 0.188690\n","J_previous: 0.064543 \tJ_current: 0.064424 \tError: 0.185287\n","J_previous: 0.064424 \tJ_current: 0.064307 \tError: 0.181970\n","J_previous: 0.064307 \tJ_current: 0.064192 \tError: 0.178735\n","J_previous: 0.064192 \tJ_current: 0.064079 \tError: 0.175582\n","J_previous: 0.064079 \tJ_current: 0.063969 \tError: 0.172506\n","J_previous: 0.063969 \tJ_current: 0.063861 \tError: 0.169506\n","J_previous: 0.063861 \tJ_current: 0.063755 \tError: 0.166579\n","J_previous: 0.063755 \tJ_current: 0.063650 \tError: 0.163722\n","J_previous: 0.063650 \tJ_current: 0.063548 \tError: 0.160934\n","J_previous: 0.063548 \tJ_current: 0.063448 \tError: 0.158212\n","J_previous: 0.063448 \tJ_current: 0.063349 \tError: 0.155554\n","J_previous: 0.063349 \tJ_current: 0.063253 \tError: 0.152959\n","J_previous: 0.063253 \tJ_current: 0.063158 \tError: 0.150424\n","J_previous: 0.063158 \tJ_current: 0.063064 \tError: 0.147948\n","J_previous: 0.063064 \tJ_current: 0.062973 \tError: 0.145529\n","J_previous: 0.062973 \tJ_current: 0.062883 \tError: 0.143164\n","J_previous: 0.062883 \tJ_current: 0.062794 \tError: 0.140854\n","J_previous: 0.062794 \tJ_current: 0.062707 \tError: 0.138595\n","J_previous: 0.062707 \tJ_current: 0.062622 \tError: 0.136386\n","J_previous: 0.062622 \tJ_current: 0.062538 \tError: 0.134227\n","J_previous: 0.062538 \tJ_current: 0.062455 \tError: 0.132115\n","J_previous: 0.062455 \tJ_current: 0.062374 \tError: 0.130050\n","J_previous: 0.062374 \tJ_current: 0.062294 \tError: 0.128029\n","J_previous: 0.062294 \tJ_current: 0.062216 \tError: 0.126052\n","J_previous: 0.062216 \tJ_current: 0.062139 \tError: 0.124117\n","J_previous: 0.062139 \tJ_current: 0.062063 \tError: 0.122223\n","J_previous: 0.062063 \tJ_current: 0.061988 \tError: 0.120370\n","J_previous: 0.061988 \tJ_current: 0.061915 \tError: 0.118556\n","J_previous: 0.061915 \tJ_current: 0.061843 \tError: 0.116779\n","J_previous: 0.061843 \tJ_current: 0.061772 \tError: 0.115039\n","J_previous: 0.061772 \tJ_current: 0.061702 \tError: 0.113336\n","J_previous: 0.061702 \tJ_current: 0.061633 \tError: 0.111667\n","J_previous: 0.061633 \tJ_current: 0.061565 \tError: 0.110032\n","J_previous: 0.061565 \tJ_current: 0.061499 \tError: 0.108430\n","J_previous: 0.061499 \tJ_current: 0.061433 \tError: 0.106861\n","J_previous: 0.061433 \tJ_current: 0.061368 \tError: 0.105323\n","J_previous: 0.061368 \tJ_current: 0.061305 \tError: 0.103816\n","J_previous: 0.061305 \tJ_current: 0.061242 \tError: 0.102338\n","J_previous: 0.061242 \tJ_current: 0.061180 \tError: 0.100889\n","J_previous: 0.061180 \tJ_current: 0.061119 \tError: 0.099469\n","J_previous: 0.061119 \tJ_current: 0.061060 \tError: 0.098076\n","J_previous: 0.061060 \tJ_current: 0.061001 \tError: 0.096711\n","J_previous: 0.061001 \tJ_current: 0.060942 \tError: 0.095371\n","J_previous: 0.060942 \tJ_current: 0.060885 \tError: 0.094057\n","J_previous: 0.060885 \tJ_current: 0.060829 \tError: 0.092768\n","J_previous: 0.060829 \tJ_current: 0.060773 \tError: 0.091503\n","J_previous: 0.060773 \tJ_current: 0.060718 \tError: 0.090262\n","J_previous: 0.060718 \tJ_current: 0.060664 \tError: 0.089044\n","J_previous: 0.060664 \tJ_current: 0.060611 \tError: 0.087849\n","J_previous: 0.060611 \tJ_current: 0.060559 \tError: 0.086676\n","J_previous: 0.060559 \tJ_current: 0.060507 \tError: 0.085524\n","J_previous: 0.060507 \tJ_current: 0.060456 \tError: 0.084394\n","J_previous: 0.060456 \tJ_current: 0.060406 \tError: 0.083283\n","J_previous: 0.060406 \tJ_current: 0.060356 \tError: 0.082193\n","J_previous: 0.060356 \tJ_current: 0.060307 \tError: 0.081123\n","J_previous: 0.060307 \tJ_current: 0.060259 \tError: 0.080071\n","J_previous: 0.060259 \tJ_current: 0.060211 \tError: 0.079039\n","J_previous: 0.060211 \tJ_current: 0.060164 \tError: 0.078024\n","J_previous: 0.060164 \tJ_current: 0.060118 \tError: 0.077027\n","J_previous: 0.060118 \tJ_current: 0.060072 \tError: 0.076048\n","J_previous: 0.060072 \tJ_current: 0.060027 \tError: 0.075086\n","J_previous: 0.060027 \tJ_current: 0.059983 \tError: 0.074140\n","J_previous: 0.059983 \tJ_current: 0.059939 \tError: 0.073211\n","J_previous: 0.059939 \tJ_current: 0.059895 \tError: 0.072298\n","J_previous: 0.059895 \tJ_current: 0.059853 \tError: 0.071400\n","J_previous: 0.059853 \tJ_current: 0.059811 \tError: 0.070517\n","J_previous: 0.059811 \tJ_current: 0.059769 \tError: 0.069650\n","J_previous: 0.059769 \tJ_current: 0.059728 \tError: 0.068797\n","J_previous: 0.059728 \tJ_current: 0.059687 \tError: 0.067958\n","J_previous: 0.059687 \tJ_current: 0.059647 \tError: 0.067133\n","J_previous: 0.059647 \tJ_current: 0.059608 \tError: 0.066322\n","J_previous: 0.059608 \tJ_current: 0.059569 \tError: 0.065524\n","J_previous: 0.059569 \tJ_current: 0.059530 \tError: 0.064739\n","J_previous: 0.059530 \tJ_current: 0.059492 \tError: 0.063967\n","J_previous: 0.059492 \tJ_current: 0.059455 \tError: 0.063207\n","J_previous: 0.059455 \tJ_current: 0.059417 \tError: 0.062460\n","J_previous: 0.059417 \tJ_current: 0.059381 \tError: 0.061725\n","J_previous: 0.059381 \tJ_current: 0.059345 \tError: 0.061001\n","J_previous: 0.059345 \tJ_current: 0.059309 \tError: 0.060289\n","J_previous: 0.059309 \tJ_current: 0.059273 \tError: 0.059589\n","J_previous: 0.059273 \tJ_current: 0.059239 \tError: 0.058899\n","J_previous: 0.059239 \tJ_current: 0.059204 \tError: 0.058220\n","J_previous: 0.059204 \tJ_current: 0.059170 \tError: 0.057552\n","J_previous: 0.059170 \tJ_current: 0.059136 \tError: 0.056894\n","J_previous: 0.059136 \tJ_current: 0.059103 \tError: 0.056246\n","J_previous: 0.059103 \tJ_current: 0.059070 \tError: 0.055609\n","J_previous: 0.059070 \tJ_current: 0.059038 \tError: 0.054981\n","J_previous: 0.059038 \tJ_current: 0.059006 \tError: 0.054363\n","J_previous: 0.059006 \tJ_current: 0.058974 \tError: 0.053754\n","J_previous: 0.058974 \tJ_current: 0.058943 \tError: 0.053154\n","J_previous: 0.058943 \tJ_current: 0.058912 \tError: 0.052563\n","J_previous: 0.058912 \tJ_current: 0.058881 \tError: 0.051982\n","J_previous: 0.058881 \tJ_current: 0.058851 \tError: 0.051409\n","J_previous: 0.058851 \tJ_current: 0.058821 \tError: 0.050844\n","J_previous: 0.058821 \tJ_current: 0.058791 \tError: 0.050288\n","J_previous: 0.058791 \tJ_current: 0.058762 \tError: 0.049740\n","J_previous: 0.058762 \tJ_current: 0.058733 \tError: 0.049200\n","J_previous: 0.058733 \tJ_current: 0.058705 \tError: 0.048668\n","J_previous: 0.058705 \tJ_current: 0.058677 \tError: 0.048144\n","J_previous: 0.058677 \tJ_current: 0.058649 \tError: 0.047627\n","J_previous: 0.058649 \tJ_current: 0.058621 \tError: 0.047118\n","J_previous: 0.058621 \tJ_current: 0.058594 \tError: 0.046616\n","J_previous: 0.058594 \tJ_current: 0.058567 \tError: 0.046121\n","J_previous: 0.058567 \tJ_current: 0.058540 \tError: 0.045634\n","J_previous: 0.058540 \tJ_current: 0.058513 \tError: 0.045153\n","J_previous: 0.058513 \tJ_current: 0.058487 \tError: 0.044679\n","J_previous: 0.058487 \tJ_current: 0.058462 \tError: 0.044212\n","J_previous: 0.058462 \tJ_current: 0.058436 \tError: 0.043751\n","J_previous: 0.058436 \tJ_current: 0.058411 \tError: 0.043297\n","J_previous: 0.058411 \tJ_current: 0.058386 \tError: 0.042849\n","J_previous: 0.058386 \tJ_current: 0.058361 \tError: 0.042408\n","J_previous: 0.058361 \tJ_current: 0.058336 \tError: 0.041972\n","J_previous: 0.058336 \tJ_current: 0.058312 \tError: 0.041542\n","J_previous: 0.058312 \tJ_current: 0.058288 \tError: 0.041119\n","J_previous: 0.058288 \tJ_current: 0.058264 \tError: 0.040701\n","J_previous: 0.058264 \tJ_current: 0.058241 \tError: 0.040288\n","J_previous: 0.058241 \tJ_current: 0.058218 \tError: 0.039882\n","J_previous: 0.058218 \tJ_current: 0.058195 \tError: 0.039481\n","J_previous: 0.058195 \tJ_current: 0.058172 \tError: 0.039085\n","J_previous: 0.058172 \tJ_current: 0.058150 \tError: 0.038694\n","J_previous: 0.058150 \tJ_current: 0.058127 \tError: 0.038309\n","J_previous: 0.058127 \tJ_current: 0.058105 \tError: 0.037929\n","J_previous: 0.058105 \tJ_current: 0.058083 \tError: 0.037554\n","J_previous: 0.058083 \tJ_current: 0.058062 \tError: 0.037184\n","J_previous: 0.058062 \tJ_current: 0.058041 \tError: 0.036818\n","J_previous: 0.058041 \tJ_current: 0.058019 \tError: 0.036458\n","J_previous: 0.058019 \tJ_current: 0.057998 \tError: 0.036102\n","J_previous: 0.057998 \tJ_current: 0.057978 \tError: 0.035751\n","J_previous: 0.057978 \tJ_current: 0.057957 \tError: 0.035404\n","J_previous: 0.057957 \tJ_current: 0.057937 \tError: 0.035062\n","J_previous: 0.057937 \tJ_current: 0.057917 \tError: 0.034724\n","J_previous: 0.057917 \tJ_current: 0.057897 \tError: 0.034391\n","J_previous: 0.057897 \tJ_current: 0.057877 \tError: 0.034061\n","J_previous: 0.057877 \tJ_current: 0.057858 \tError: 0.033737\n","J_previous: 0.057858 \tJ_current: 0.057838 \tError: 0.033416\n","J_previous: 0.057838 \tJ_current: 0.057819 \tError: 0.033099\n","J_previous: 0.057819 \tJ_current: 0.057800 \tError: 0.032786\n","J_previous: 0.057800 \tJ_current: 0.057781 \tError: 0.032477\n","J_previous: 0.057781 \tJ_current: 0.057763 \tError: 0.032172\n","J_previous: 0.057763 \tJ_current: 0.057744 \tError: 0.031871\n","J_previous: 0.057744 \tJ_current: 0.057726 \tError: 0.031573\n","J_previous: 0.057726 \tJ_current: 0.057708 \tError: 0.031279\n","J_previous: 0.057708 \tJ_current: 0.057690 \tError: 0.030989\n","J_previous: 0.057690 \tJ_current: 0.057673 \tError: 0.030702\n","J_previous: 0.057673 \tJ_current: 0.057655 \tError: 0.030419\n","J_previous: 0.057655 \tJ_current: 0.057638 \tError: 0.030139\n","J_previous: 0.057638 \tJ_current: 0.057620 \tError: 0.029863\n","J_previous: 0.057620 \tJ_current: 0.057603 \tError: 0.029590\n","J_previous: 0.057603 \tJ_current: 0.057587 \tError: 0.029320\n","J_previous: 0.057587 \tJ_current: 0.057570 \tError: 0.029054\n","J_previous: 0.057570 \tJ_current: 0.057553 \tError: 0.028791\n","J_previous: 0.057553 \tJ_current: 0.057537 \tError: 0.028531\n","J_previous: 0.057537 \tJ_current: 0.057521 \tError: 0.028274\n","J_previous: 0.057521 \tJ_current: 0.057504 \tError: 0.028020\n","J_previous: 0.057504 \tJ_current: 0.057488 \tError: 0.027769\n","J_previous: 0.057488 \tJ_current: 0.057473 \tError: 0.027521\n","J_previous: 0.057473 \tJ_current: 0.057457 \tError: 0.027276\n","J_previous: 0.057457 \tJ_current: 0.057441 \tError: 0.027033\n","J_previous: 0.057441 \tJ_current: 0.057426 \tError: 0.026794\n","J_previous: 0.057426 \tJ_current: 0.057411 \tError: 0.026557\n","J_previous: 0.057411 \tJ_current: 0.057396 \tError: 0.026324\n","J_previous: 0.057396 \tJ_current: 0.057381 \tError: 0.026093\n","J_previous: 0.057381 \tJ_current: 0.057366 \tError: 0.025864\n","J_previous: 0.057366 \tJ_current: 0.057351 \tError: 0.025638\n","J_previous: 0.057351 \tJ_current: 0.057337 \tError: 0.025415\n","J_previous: 0.057337 \tJ_current: 0.057322 \tError: 0.025194\n","J_previous: 0.057322 \tJ_current: 0.057308 \tError: 0.024976\n","J_previous: 0.057308 \tJ_current: 0.057294 \tError: 0.024760\n","J_previous: 0.057294 \tJ_current: 0.057280 \tError: 0.024547\n","J_previous: 0.057280 \tJ_current: 0.057266 \tError: 0.024336\n","J_previous: 0.057266 \tJ_current: 0.057252 \tError: 0.024128\n","J_previous: 0.057252 \tJ_current: 0.057238 \tError: 0.023922\n","J_previous: 0.057238 \tJ_current: 0.057225 \tError: 0.023718\n","J_previous: 0.057225 \tJ_current: 0.057211 \tError: 0.023516\n","J_previous: 0.057211 \tJ_current: 0.057198 \tError: 0.023317\n","J_previous: 0.057198 \tJ_current: 0.057185 \tError: 0.023120\n","J_previous: 0.057185 \tJ_current: 0.057172 \tError: 0.022925\n","J_previous: 0.057172 \tJ_current: 0.057159 \tError: 0.022732\n","J_previous: 0.057159 \tJ_current: 0.057146 \tError: 0.022541\n","J_previous: 0.057146 \tJ_current: 0.057133 \tError: 0.022353\n","J_previous: 0.057133 \tJ_current: 0.057120 \tError: 0.022166\n","J_previous: 0.057120 \tJ_current: 0.057108 \tError: 0.021982\n","J_previous: 0.057108 \tJ_current: 0.057095 \tError: 0.021799\n","J_previous: 0.057095 \tJ_current: 0.057083 \tError: 0.021619\n","J_previous: 0.057083 \tJ_current: 0.057071 \tError: 0.021440\n","J_previous: 0.057071 \tJ_current: 0.057058 \tError: 0.021263\n","J_previous: 0.057058 \tJ_current: 0.057046 \tError: 0.021089\n","J_previous: 0.057046 \tJ_current: 0.057035 \tError: 0.020916\n","J_previous: 0.057035 \tJ_current: 0.057023 \tError: 0.020745\n","J_previous: 0.057023 \tJ_current: 0.057011 \tError: 0.020575\n","J_previous: 0.057011 \tJ_current: 0.056999 \tError: 0.020408\n","J_previous: 0.056999 \tJ_current: 0.056988 \tError: 0.020242\n","J_previous: 0.056988 \tJ_current: 0.056976 \tError: 0.020078\n","J_previous: 0.056976 \tJ_current: 0.056965 \tError: 0.019916\n","J_previous: 0.056965 \tJ_current: 0.056954 \tError: 0.019756\n","J_previous: 0.056954 \tJ_current: 0.056943 \tError: 0.019597\n","J_previous: 0.056943 \tJ_current: 0.056932 \tError: 0.019440\n","J_previous: 0.056932 \tJ_current: 0.056921 \tError: 0.019284\n","J_previous: 0.056921 \tJ_current: 0.056910 \tError: 0.019130\n","J_previous: 0.056910 \tJ_current: 0.056899 \tError: 0.018978\n","J_previous: 0.056899 \tJ_current: 0.056888 \tError: 0.018827\n","J_previous: 0.056888 \tJ_current: 0.056878 \tError: 0.018678\n","J_previous: 0.056878 \tJ_current: 0.056867 \tError: 0.018530\n","J_previous: 0.056867 \tJ_current: 0.056857 \tError: 0.018384\n","J_previous: 0.056857 \tJ_current: 0.056846 \tError: 0.018240\n","J_previous: 0.056846 \tJ_current: 0.056836 \tError: 0.018096\n","J_previous: 0.056836 \tJ_current: 0.056826 \tError: 0.017955\n","J_previous: 0.056826 \tJ_current: 0.056816 \tError: 0.017814\n","J_previous: 0.056816 \tJ_current: 0.056806 \tError: 0.017675\n","J_previous: 0.056806 \tJ_current: 0.056796 \tError: 0.017538\n","J_previous: 0.056796 \tJ_current: 0.056786 \tError: 0.017402\n","J_previous: 0.056786 \tJ_current: 0.056776 \tError: 0.017267\n","J_previous: 0.056776 \tJ_current: 0.056766 \tError: 0.017133\n","J_previous: 0.056766 \tJ_current: 0.056757 \tError: 0.017002\n","J_previous: 0.056757 \tJ_current: 0.056747 \tError: 0.016871\n","J_previous: 0.056747 \tJ_current: 0.056737 \tError: 0.016741\n","J_previous: 0.056737 \tJ_current: 0.056728 \tError: 0.016613\n","J_previous: 0.056728 \tJ_current: 0.056719 \tError: 0.016486\n","J_previous: 0.056719 \tJ_current: 0.056709 \tError: 0.016360\n","J_previous: 0.056709 \tJ_current: 0.056700 \tError: 0.016236\n","J_previous: 0.056700 \tJ_current: 0.056691 \tError: 0.016113\n","J_previous: 0.056691 \tJ_current: 0.056682 \tError: 0.015991\n","J_previous: 0.056682 \tJ_current: 0.056673 \tError: 0.015870\n","J_previous: 0.056673 \tJ_current: 0.056664 \tError: 0.015750\n","J_previous: 0.056664 \tJ_current: 0.056655 \tError: 0.015632\n","J_previous: 0.056655 \tJ_current: 0.056646 \tError: 0.015514\n","J_previous: 0.056646 \tJ_current: 0.056638 \tError: 0.015398\n","J_previous: 0.056638 \tJ_current: 0.056629 \tError: 0.015283\n","J_previous: 0.056629 \tJ_current: 0.056620 \tError: 0.015169\n","J_previous: 0.056620 \tJ_current: 0.056612 \tError: 0.015056\n","J_previous: 0.056612 \tJ_current: 0.056603 \tError: 0.014944\n","J_previous: 0.056603 \tJ_current: 0.056595 \tError: 0.014833\n","J_previous: 0.056595 \tJ_current: 0.056587 \tError: 0.014724\n","J_previous: 0.056587 \tJ_current: 0.056578 \tError: 0.014615\n","J_previous: 0.056578 \tJ_current: 0.056570 \tError: 0.014507\n","J_previous: 0.056570 \tJ_current: 0.056562 \tError: 0.014401\n","J_previous: 0.056562 \tJ_current: 0.056554 \tError: 0.014295\n","J_previous: 0.056554 \tJ_current: 0.056546 \tError: 0.014191\n","J_previous: 0.056546 \tJ_current: 0.056538 \tError: 0.014087\n","J_previous: 0.056538 \tJ_current: 0.056530 \tError: 0.013984\n","J_previous: 0.056530 \tJ_current: 0.056522 \tError: 0.013882\n","J_previous: 0.056522 \tJ_current: 0.056515 \tError: 0.013782\n","J_previous: 0.056515 \tJ_current: 0.056507 \tError: 0.013682\n","J_previous: 0.056507 \tJ_current: 0.056499 \tError: 0.013583\n","J_previous: 0.056499 \tJ_current: 0.056491 \tError: 0.013485\n","J_previous: 0.056491 \tJ_current: 0.056484 \tError: 0.013388\n","J_previous: 0.056484 \tJ_current: 0.056476 \tError: 0.013291\n","J_previous: 0.056476 \tJ_current: 0.056469 \tError: 0.013196\n","J_previous: 0.056469 \tJ_current: 0.056462 \tError: 0.013101\n","J_previous: 0.056462 \tJ_current: 0.056454 \tError: 0.013008\n","J_previous: 0.056454 \tJ_current: 0.056447 \tError: 0.012915\n","J_previous: 0.056447 \tJ_current: 0.056440 \tError: 0.012823\n","J_previous: 0.056440 \tJ_current: 0.056433 \tError: 0.012732\n","J_previous: 0.056433 \tJ_current: 0.056425 \tError: 0.012642\n","J_previous: 0.056425 \tJ_current: 0.056418 \tError: 0.012552\n","J_previous: 0.056418 \tJ_current: 0.056411 \tError: 0.012464\n","J_previous: 0.056411 \tJ_current: 0.056404 \tError: 0.012376\n","J_previous: 0.056404 \tJ_current: 0.056397 \tError: 0.012289\n","J_previous: 0.056397 \tJ_current: 0.056390 \tError: 0.012203\n","J_previous: 0.056390 \tJ_current: 0.056384 \tError: 0.012117\n","J_previous: 0.056384 \tJ_current: 0.056377 \tError: 0.012032\n","J_previous: 0.056377 \tJ_current: 0.056370 \tError: 0.011948\n","J_previous: 0.056370 \tJ_current: 0.056363 \tError: 0.011865\n","J_previous: 0.056363 \tJ_current: 0.056357 \tError: 0.011782\n","J_previous: 0.056357 \tJ_current: 0.056350 \tError: 0.011701\n","J_previous: 0.056350 \tJ_current: 0.056344 \tError: 0.011619\n","J_previous: 0.056344 \tJ_current: 0.056337 \tError: 0.011539\n","J_previous: 0.056337 \tJ_current: 0.056331 \tError: 0.011459\n","J_previous: 0.056331 \tJ_current: 0.056324 \tError: 0.011380\n","J_previous: 0.056324 \tJ_current: 0.056318 \tError: 0.011302\n","J_previous: 0.056318 \tJ_current: 0.056312 \tError: 0.011224\n","J_previous: 0.056312 \tJ_current: 0.056305 \tError: 0.011148\n","J_previous: 0.056305 \tJ_current: 0.056299 \tError: 0.011071\n","J_previous: 0.056299 \tJ_current: 0.056293 \tError: 0.010995\n","J_previous: 0.056293 \tJ_current: 0.056287 \tError: 0.010921\n","J_previous: 0.056287 \tJ_current: 0.056281 \tError: 0.010846\n","J_previous: 0.056281 \tJ_current: 0.056275 \tError: 0.010773\n","J_previous: 0.056275 \tJ_current: 0.056269 \tError: 0.010700\n","J_previous: 0.056269 \tJ_current: 0.056263 \tError: 0.010627\n","J_previous: 0.056263 \tJ_current: 0.056257 \tError: 0.010555\n","J_previous: 0.056257 \tJ_current: 0.056251 \tError: 0.010484\n","J_previous: 0.056251 \tJ_current: 0.056245 \tError: 0.010414\n","J_previous: 0.056245 \tJ_current: 0.056239 \tError: 0.010344\n","J_previous: 0.056239 \tJ_current: 0.056233 \tError: 0.010274\n","J_previous: 0.056233 \tJ_current: 0.056228 \tError: 0.010206\n","J_previous: 0.056228 \tJ_current: 0.056222 \tError: 0.010137\n","J_previous: 0.056222 \tJ_current: 0.056216 \tError: 0.010069\n","J_previous: 0.056216 \tJ_current: 0.056211 \tError: 0.010003\n","J_previous: 0.056211 \tJ_current: 0.056205 \tError: 0.009936\n"]}],"source":["# Crea una instancia del modelo NeuronModel con los datos de entrenamiento y parámetros especificados\n","model = NeuronModel(X=X_train, y=y_train, learning_rate=1, error_threshold=0.01)\n","\n","# Entrena el modelo, mostrando información detallada durante el proceso\n","model.train(verbose=1)\n"]},{"cell_type":"markdown","metadata":{},"source":["El output de este bloque es una gráfica que muestra el costo en el eje vertical (y) en función de las iteraciones en el eje horizontal (x)."]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":452},"executionInfo":{"elapsed":785,"status":"ok","timestamp":1726229560744,"user":{"displayName":"Andrés Hernández Gutiérrez","userId":"09168378548171975941"},"user_tz":-600},"id":"SW9hZDqqQisx","outputId":"aaa5c50f-e86b-47cc-8fdd-f061b509ae67"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Grafica la función de costo a lo largo de las iteraciones del entrenamiento\n","model.plot_cost_function()\n"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":289,"status":"ok","timestamp":1726229564958,"user":{"displayName":"Andrés Hernández Gutiérrez","userId":"09168378548171975941"},"user_tz":-600},"id":"Xi1dSaZBQisx"},"outputs":[],"source":["# Realiza predicciones sobre el conjunto de datos de prueba utilizando el modelo entrenado\n","y_predictions = model.predict(X=X_test)\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":424,"status":"ok","timestamp":1726229566800,"user":{"displayName":"Andrés Hernández Gutiérrez","userId":"09168378548171975941"},"user_tz":-600},"id":"gr9mNSCzQisx","outputId":"6d3a869d-9344-4cf6-9629-e0c073658b7f"},"outputs":[],"source":["# Obtiene los parámetros del modelo (pesos y sesgo) después del entrenamiento\n","parameters = model.get_parameters()\n"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"A22D2s2PQisx","outputId":"60daca34-5f6a-429b-f0f3-9e20250f2af3"},"outputs":[{"data":{"text/plain":["0.9892996108949417"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["# Evalúa el rendimiento del modelo comparando las predicciones con los datos reales de prueba\n","model.evaluate(y_hat=y_predictions, y=y_test)\n"]},{"cell_type":"markdown","metadata":{},"source":["El output muestra que el modelo tiene un rendimiento excepcional en la detección de ocupación, con una exactitud del 98.93%, lo que significa que casi todas las predicciones son correctas. La precisión es del 95.76%, indicando que cuando el modelo predice ocupación, es altamente confiable. Con un recall de 99.68%, casi todas las instancias de ocupación son detectadas. La especificidad es del 98.71%, lo que refleja la capacidad del modelo para identificar correctamente los casos sin ocupación. Finalmente, el F1-score de 97.68% sugiere un buen equilibrio entre precisión y recall, haciendo del modelo una herramienta efectiva para aplicaciones prácticas."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"Sz0n37YNQisy"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.9893\n","Precision: 0.9576\n","Recall: 0.9968\n","Specificity: 0.9871\n","F1-score: 0.9768\n"]}],"source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","\n","# Calcula las predicciones binarias a partir de las probabilidades\n","y_pred_binary = (y_predictions >= 0.5).astype(int)\n","\n","# Calcula las métricas de rendimiento\n","accuracy = accuracy_score(y_test, y_pred_binary)\n","precision = precision_score(y_test, y_pred_binary)\n","recall = recall_score(y_test, y_pred_binary)\n","conf_matrix = confusion_matrix(y_test, y_pred_binary)\n","\n","# Especificidad se calcula a partir de la matriz de confusión\n","specificity = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])  # Verdaderos negativos / (VN + FP)\n","\n","f1 = f1_score(y_test, y_pred_binary)\n","\n","# Imprime las métricas\n","print(f\"Accuracy: {accuracy:.4f}\")\n","print(f\"Precision: {precision:.4f}\")\n","print(f\"Recall: {recall:.4f}\")\n","print(f\"Specificity: {specificity:.4f}\")\n","print(f\"F1-score: {f1:.4f}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["Conclusiones sobre los modelos: Después de evaluar los dos modelos, el desarrollado en TensorFlow se considera el mejor por varias razones. En primer lugar, las métricas de rendimiento del modelo de TensorFlow son ligeramente superiores en aspectos clave como la accuracy (0.989543 frente a 0.9893), precision (0.958635 frente a 0.9576) y F1-score (0.977333 frente a 0.9768). Aunque las diferencias son pequeñas, reflejan una capacidad ligeramente mayor para clasificar correctamente las instancias. Además, TensorFlow está optimizada y es ampliamente utilizada para el desarrollo de modelos de aprendizaje profundo, lo que le permite ofrecer herramientas avanzadas de regularización y optimización que pueden mejorar la generalización en datos no vistos, de igual forma TensorFlow permite que el modelo se adapte a conjuntos de datos más grandes y complejos."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"ai","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":0}
